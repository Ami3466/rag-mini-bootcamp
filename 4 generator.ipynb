{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "def display_md(content):\n",
    "  display(Markdown(content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators and generators.py\n",
    "Now that you've retrieved the context needed for your query, the only step left is to prompt your LLM with the retrieved context appropriately. In a production setting, you may spend some time optimizing your prompt with techniques like Chain of Thought or using prompt compilation with DSPy. Generally, the better the inference performance you are trying to get out of a smaller model, the more optimization you will have to do to achieve acceptable performance.\n",
    "\n",
    "The following cheat code should work if you're run your indexer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Naive RAG is the earliest methodology in the RAG research paradigm, following a traditional process of indexing, retrieval, and generation. Advanced RAG and Modular RAG were developed to address specific shortcomings in Naive RAG by offering more adaptability and flexibility through module substitution and reconfiguration. Advanced RAG enhances the retrieval process by incorporating new modules and adjusting interaction flows, improving task performance and relevance of retrieved information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cheat_code.common_components.vectorizers import Vectorizer\n",
    "from cheat_code.retrievers import NaiveRetriever\n",
    "from cheat_code.generators import NaiveGenerator\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "retriever = NaiveRetriever(vectorizer)\n",
    "generator = NaiveGenerator()\n",
    "\n",
    "query = \"What's the difference between Naive RAG and Advanced RAG?\"\n",
    "retrieved_context = retriever.retrieve(query)\n",
    "completion = generator.get_completion(query, retrieved_context)\n",
    "display_md(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Write a system prompt and prompt for the LLM that combines your query with the retrieved context\n",
    "Modify the code in `./workshop_code/generators.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Implement this method and delete this exception.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m generator \u001b[38;5;241m=\u001b[39m NaiveGenerator()\n\u001b[1;32m      9\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms the difference between Naive RAG and Advanced RAG?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m retrieved_context \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m completion \u001b[38;5;241m=\u001b[39m generator\u001b[38;5;241m.\u001b[39mget_completion(query, retrieved_context)\n\u001b[1;32m     12\u001b[0m display_md(completion)\n",
      "File \u001b[0;32m~/src/rag-mini-bootcamp/workshop_code/retrievers.py:11\u001b[0m, in \u001b[0;36mNaiveRetriever.retrieve\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 11\u001b[0m   query_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorize_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m   retrieved_chunks_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wcs_client_adapter\u001b[38;5;241m.\u001b[39mretrieve(query_vector, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     13\u001b[0m   formatted_chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunk \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m retrieved_chunks_list)\n",
      "File \u001b[0;32m~/src/rag-mini-bootcamp/workshop_code/common_components/vectorizers.py:17\u001b[0m, in \u001b[0;36mVectorizer.vectorize_query\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvectorize_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplement this method and delete this exception.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# response = ???  # TODO: write the API call to the OpenAI Embeddings API\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     query_vector \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39membedding\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Implement this method and delete this exception."
     ]
    }
   ],
   "source": [
    "from workshop_code.common_components.vectorizers import Vectorizer\n",
    "from workshop_code.retrievers import NaiveRetriever\n",
    "from workshop_code.generators import NaiveGenerator\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "retriever = NaiveRetriever(vectorizer)\n",
    "generator = NaiveGenerator()\n",
    "\n",
    "query = \"What's the difference between Naive RAG and Advanced RAG?\"\n",
    "retrieved_context = retriever.retrieve(query)\n",
    "completion = generator.get_completion(query, retrieved_context)\n",
    "display_md(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
